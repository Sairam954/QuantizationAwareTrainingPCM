{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "QATPCM.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyPp+QhAb/Fh8E/BC5a91PNK",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Sairam954/QuantizationAwareTrainingPCM/blob/master/QATPCM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H2RVttGv8IWE",
    "colab_type": "code",
    "outputId": "0257c89f-30bf-45ab-a335-72d0b096674e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    }
   },
   "source": [
    "pip install git+https://github.com/Xilinx/brevitas.git"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Xilinx/brevitas.git\n",
      "  Cloning https://github.com/Xilinx/brevitas.git to /tmp/pip-req-build-wsyhbjtw\n",
      "  Running command git clone -q https://github.com/Xilinx/brevitas.git /tmp/pip-req-build-wsyhbjtw\n",
      "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Brevitas==0.2.0a0) (1.4.0)\n",
      "Collecting docrep\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/4a/ac09d6e07713e22baa4ab4e6f422d25e53425f3dc042616387dfbc272504/docrep-0.2.7.tar.gz\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from Brevitas==0.2.0a0) (1.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from Brevitas==0.2.0a0) (20.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from docrep->Brevitas==0.2.0a0) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->Brevitas==0.2.0a0) (1.17.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->Brevitas==0.2.0a0) (2.4.6)\n",
      "Building wheels for collected packages: Brevitas, docrep\n",
      "  Building wheel for Brevitas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for Brevitas: filename=Brevitas-0.2.0a0-cp36-cp36m-linux_x86_64.whl size=1748363 sha256=879092cd9e31e8b8fcc77e1cd031c15ba0bac0091352199234b526a92d5946a1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-igs3wal0/wheels/7b/ba/1b/b3bebdeb51db39fc118c4d60ef8556d8a9ab0f1bfda8767a3d\n",
      "  Building wheel for docrep (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docrep: filename=docrep-0.2.7-cp36-none-any.whl size=23003 sha256=7192537d9a6e10ac52deb9b33c8ec33aeea694c2ab9868240c6a6624054d8535\n",
      "  Stored in directory: /root/.cache/pip/wheels/43/6c/2a/d7b1c8a6e7e66f708a6b6a4fbe4bb5a73219f9c7f0afed568b\n",
      "Successfully built Brevitas docrep\n",
      "Installing collected packages: docrep, Brevitas\n",
      "Successfully installed Brevitas-0.2.0a0 docrep-0.2.7\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7LQgaz4J-WqI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.quantization"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bk5JaehW6-JN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.core.quant import QuantType\n",
    "\n",
    "class QuantLeNet(Module):\n",
    "    def __init__(self):\n",
    "        super(QuantLeNet, self).__init__()\n",
    "        self.conv1 = qnn.QuantConv2d(1, 6, 5, \n",
    "                                     weight_quant_type=QuantType.FP, \n",
    "                                     weight_bit_width=4)\n",
    "        self.relu1 = qnn.QuantReLU(quant_type=QuantType.FP, bit_width=4, max_val=6)\n",
    "        self.conv2 = qnn.QuantConv2d(6, 16, 5, \n",
    "                                     weight_quant_type=QuantType.FP, \n",
    "                                     weight_bit_width=4)\n",
    "        self.relu2 = qnn.QuantReLU(quant_type=QuantType.FP, bit_width=4, max_val=6)\n",
    "        self.fc1   = qnn.QuantLinear(256, 120, bias=True, \n",
    "                                     weight_quant_type=QuantType.FP, \n",
    "                                     weight_bit_width=4)\n",
    "        self.relu3 = qnn.QuantReLU(quant_type=QuantType.FP, bit_width=4, max_val=6)\n",
    "        self.fc2   = qnn.QuantLinear(120, 84, bias=True, \n",
    "                                     weight_quant_type=QuantType.FP, \n",
    "                                     weight_bit_width=4)\n",
    "        self.relu4 = qnn.QuantReLU(quant_type=QuantType.FP, bit_width=4, max_val=6)\n",
    "        self.fc3   = qnn.QuantLinear(84, 10, bias=False, \n",
    "                                     weight_quant_type=QuantType.FP, \n",
    "                                     weight_bit_width=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = self.relu2(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.relu3(self.fc1(out))\n",
    "        out = self.relu4(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    def printcheck(self):\n",
    "        print(self.conv1.shape)\n",
    "        print(self.conv2.shape)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "      \n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oOPJk-Gj-Bbg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def evaluation(dataloader,model):\n",
    "    total, correct = 0, 0\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "    return 100 * correct / total\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ww_FDPM27I66",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "klist = []\n",
    "vlist = []\n",
    "kstd = []\n",
    "vstd = []\n",
    "\n",
    "# initialise K and v for the model with C2C and D2D variation for a specific model\n",
    "\n",
    "def intialiseVandK(model):\n",
    "  vdict ={}\n",
    "  kdict ={}\n",
    "  for name,currentweight in model.named_parameters():\n",
    "          with torch.no_grad(): \n",
    "            vmin = 0.1\n",
    "            vmax =0.125\n",
    "            kmin = 0.2\n",
    "            kmax = 0.25\n",
    "       \n",
    "       \n",
    "            vdict[name]=torch.from_numpy(np.random.uniform(vmin,vmax,currentweight.shape))\n",
    "            kdict[name] =torch.from_numpy(np.random.uniform(kmin,kmax,currentweight.shape))\n",
    "\n",
    "\n",
    "\n",
    "  return vdict,kdict\n",
    "\n",
    "def updateWeightsWithTimePCM(model,vdict,kdict,t):\n",
    "        t0= 1e-3\n",
    "        g0 = 0.5e-06\n",
    "        #weight and resistance drift PCM model\n",
    "        minweight = -1\n",
    "        maxweight= 1\n",
    "        minmaxweightdiff= maxweight-minweight\n",
    "        minconductance = 0.554e-06\n",
    "        maxconductance = 4.762e-06\n",
    "        minmaxconductancedratio = minconductance/maxconductance\n",
    "        newmodelstate = model.state_dict()\n",
    "\n",
    "        for name,currentweight in model.named_parameters():\n",
    "            with torch.no_grad(): \n",
    "            \n",
    "              v0=vdict[name]\n",
    "              k =kdict[name]\n",
    "              v_of_w= v0 + k*np.log((g0/maxconductance)/(((currentweight-maxweight)/minmaxweightdiff)*(1-minmaxconductancedratio)+1))\n",
    "              klist.append(torch.mean(k))\n",
    "              kstd.append(torch.std(k))\n",
    "              vlist.append(torch.mean(v0))\n",
    "              vstd.append(torch.std(v0))\n",
    "              # print(np.log((g0/maxconductance)/(((currentweight-maxweight)/minmaxweightdiff)*(1-minmaxconductancedratio)+1)))\n",
    "              # print(((minmaxweightdiff/(1-minmaxconductancedratio)- maxweight))*((t/t0)**(-v_of_w)-1))\n",
    "              newweight = currentweight + (currentweight+(minmaxweightdiff/(1-minmaxconductancedratio)- maxweight))*((t/t0)**(-v_of_w)-1)\n",
    "              newmodelstate[name] = newweight\n",
    "              # print(currentweight)\n",
    "              # print(\"==============================\")\n",
    "              # print(newweight)\n",
    "        return newmodelstate\n",
    "def updateWeightWithCycleVariation(model,vdict,kdict):\n",
    "    # g0 varies with time to time \n",
    "    gmax = 0.42e-06\n",
    "    gmin = 0.58e-06\n",
    "    t=1\n",
    "    minweight = -1\n",
    "    maxweight= 1\n",
    "    minmaxweightdiff= maxweight-minweight\n",
    "    minconductance = 0.554e-06\n",
    "    maxconductance = 4.762e-06\n",
    "    minmaxconductancedratio = minconductance/maxconductance\n",
    "    newmodelstate = model.state_dict()\n",
    "    for name,currentweight in model.named_parameters():\n",
    "          with torch.no_grad(): \n",
    "          \n",
    "            v0=vdict[name]\n",
    "            k =kdict[name]\n",
    "            g0 = np.random.uniform(gmin,gmax,currentweight.shape)\n",
    "            v_of_w= v0 + k*np.log((g0/maxconductance)/(((currentweight-maxweight)/minmaxweightdiff)*(1-minmaxconductancedratio)+1))\n",
    "            klist.append(torch.mean(k))\n",
    "            kstd.append(torch.std(k))\n",
    "            vlist.append(torch.mean(v0))\n",
    "            vstd.append(torch.std(v0))\n",
    "            newweight = currentweight + (currentweight+(minmaxweightdiff/(1-minmaxconductancedratio)- maxweight))*((t/t0)**(-v_of_w)-1)\n",
    "            newmodelstate[name] = newweight\n",
    "    return newmodelstate"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EAhZrPY47FGE",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "batch_size = 128\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nVFxdljS-qZ-",
    "colab_type": "code",
    "outputId": "3e367882-b552-46d1-9823-8d628863cedc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "intmodel = QuantLeNet()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(intmodel.parameters())"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "cpu\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "otfuLA4E--rZ",
    "colab_type": "code",
    "outputId": "32a081e0-356a-4557-98cf-c65f588c682c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    }
   },
   "source": [
    "%%time\n",
    "max_epochs = 5\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        outputs = intmodel(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        #net.apply(clamp)\n",
    "        \n",
    "    print('Epoch: %d/%d' % (epoch, max_epochs))\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch: 0/5\n",
      "Epoch: 1/5\n",
      "Epoch: 2/5\n",
      "Epoch: 3/5\n",
      "Epoch: 4/5\n",
      "CPU times: user 1min 25s, sys: 2.12 s, total: 1min 27s\n",
      "Wall time: 1min 28s\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "So6x7qqM_8Y8",
    "colab_type": "code",
    "outputId": "c1bb56e2-9c85-46cc-b0fb-a10a36d920ad",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "print('Test acc: %0.2f, Train acc: %0.2f' % (evaluation(testloader,intmodel), evaluation(trainloader,intmodel)))"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Test acc: 98.73, Train acc: 98.76\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tNMdrdoWNYIF",
    "colab_type": "code",
    "outputId": "b0eaab09-4834-4b94-d0f3-cf592e14db46",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "driftedmodel = QuantLeNet() # this can be any NN architecture as long as its implemented with PyTorch nn.module\n",
    "vdict,kdict = intialiseVandK(driftedmodel)# intialising the k and v value\n",
    "t = 1e-03 # drift time\n",
    "driftedmodelstatedict = updateWeightsWithTimePCM(trainedmodel,vdict,kdict,t) # returns the state dictionary of the model with changed weights afte time t\n",
    "driftedmodel.load_state_dict(driftedmodelstatedict)# use the state dictionary to create the model with changed weights\n",
    "\n",
    "cycletocycledriftstatedict = updateWeightWithCycleVariation(trainedmodel,vdict,kdict)\n",
    "driftedmodel.load_state_dict(driftedmodelstatedict)# use the state dictionary to create the model with changed weights"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 53
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C6p5Dbq2DGst",
    "colab_type": "code",
    "outputId": "fdde4749-ecbd-4229-9874-d0968e754a5d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "print(driftedmodel.state_dict().keys())\n",
    "print(intmodel.state_dict()['fc3.weight'])\n",
    "print(\"====================================================\")\n",
    "print(driftedmodel.state_dict()['fc3.weight'])"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight'])\n",
      "tensor([[ 5.7502e-02, -4.7653e-02, -8.4562e-02, -2.5373e-02,  5.7231e-02,\n",
      "         -2.3991e-01, -5.8743e-02,  1.3909e-01,  3.4454e-02, -1.2096e-02,\n",
      "         -3.5502e-02, -1.2316e-01, -6.2097e-03, -7.2736e-02,  7.9141e-02,\n",
      "          1.6031e-02,  1.3602e-01, -1.0817e-01, -1.3844e-01,  2.8183e-02,\n",
      "         -1.0384e-01, -2.7578e-01,  1.7877e-01, -1.6349e-01, -1.2095e-01,\n",
      "          2.6431e-02, -1.1178e-01, -2.9428e-02,  6.2005e-02, -1.5256e-01,\n",
      "          6.1777e-02, -7.3393e-02, -1.9656e-01,  6.7498e-02, -1.2652e-02,\n",
      "          1.1367e-01, -3.6797e-02, -2.3679e-02,  1.5724e-01,  1.0304e-01,\n",
      "         -1.5883e-01, -7.2645e-02, -9.6742e-02,  6.9922e-02,  2.8612e-02,\n",
      "          7.6805e-02,  5.4769e-02,  5.9486e-02, -3.2537e-02,  1.4885e-01,\n",
      "         -4.3388e-02,  2.4472e-02, -4.7109e-02,  2.8444e-02,  2.4384e-03,\n",
      "         -1.3648e-01,  1.1871e-02, -6.9804e-02, -1.2491e-02,  5.7567e-02,\n",
      "         -2.4205e-02,  2.0895e-02, -7.3688e-02, -7.9895e-02, -8.4406e-02,\n",
      "          1.3331e-01,  1.5363e-01,  1.8983e-01, -2.1542e-01, -9.2696e-03,\n",
      "         -1.2719e-01, -5.7508e-02,  7.7498e-02,  3.0380e-02,  2.2764e-02,\n",
      "         -4.8476e-02, -3.9109e-02,  3.0797e-02, -1.1032e-01,  3.0609e-02,\n",
      "          2.0946e-01, -1.4476e-01, -1.5267e-01, -1.2615e-01],\n",
      "        [-1.0983e-01, -1.6643e-02, -5.4499e-02,  5.2598e-02,  1.1222e-01,\n",
      "          1.8281e-01, -1.6932e-01, -1.0697e-01, -1.5967e-01,  2.5727e-02,\n",
      "         -9.5816e-02, -1.7568e-02,  1.4565e-03, -1.1926e-01, -2.4998e-01,\n",
      "          8.7458e-03,  5.1587e-02,  1.2225e-01, -5.8399e-02,  8.9523e-02,\n",
      "          1.5307e-02,  1.0511e-01,  1.6931e-01, -1.0654e-01,  1.9253e-01,\n",
      "         -1.1609e-01, -1.1423e-02, -8.1835e-02,  2.6023e-02, -1.5318e-01,\n",
      "          1.0242e-01,  5.6021e-02, -2.4122e-02,  1.2591e-01, -1.9811e-01,\n",
      "         -1.2534e-01, -3.3369e-02, -2.6970e-01, -1.7313e-01, -1.3248e-01,\n",
      "         -6.7860e-02, -8.1787e-02, -1.0105e-01, -8.6901e-02,  1.2492e-01,\n",
      "          5.9038e-02,  7.3593e-02, -1.0772e-01, -8.4726e-03,  7.8861e-02,\n",
      "         -8.6169e-02, -9.9107e-02, -4.6772e-02,  1.0534e-01, -1.1536e-01,\n",
      "          3.9013e-02,  1.6768e-01,  3.9793e-02, -2.1685e-01,  1.6369e-01,\n",
      "         -2.1570e-01, -9.1211e-02, -5.6152e-02,  1.2030e-01,  4.9114e-02,\n",
      "         -1.0417e-01, -1.0169e-02,  3.5655e-02,  7.7145e-02,  1.5954e-01,\n",
      "          2.0149e-01,  1.4767e-01,  1.1135e-01, -2.6222e-02,  6.5729e-02,\n",
      "         -1.3869e-01, -1.0216e-01,  3.3140e-01, -9.7850e-02,  2.3685e-02,\n",
      "          1.5255e-01,  9.1470e-03, -1.1895e-01,  8.7839e-02],\n",
      "        [-1.1059e-01,  6.4744e-03,  6.7646e-02, -8.5198e-02, -3.6996e-02,\n",
      "          3.8133e-02,  1.4229e-01,  1.0586e-01, -7.2759e-02, -9.3293e-02,\n",
      "          5.8428e-02,  2.9989e-02,  1.7277e-02, -4.3939e-02, -4.3254e-02,\n",
      "          1.3321e-01,  9.4943e-02, -1.7466e-01, -5.1416e-03,  5.8932e-02,\n",
      "         -1.0059e-02, -1.2247e-01, -2.3295e-01, -1.3186e-01, -1.1138e-01,\n",
      "          5.2414e-02,  1.6524e-02, -6.7446e-02, -6.9809e-02, -3.7493e-02,\n",
      "          1.3993e-01,  1.7652e-02,  9.3298e-02,  1.3817e-01, -1.1945e-02,\n",
      "          8.6820e-02, -2.6956e-02,  1.2588e-01, -5.3166e-02, -4.8333e-02,\n",
      "         -1.1508e-01,  1.2482e-01, -4.6368e-02, -5.9391e-04, -3.2709e-02,\n",
      "         -1.4332e-01, -2.6776e-01, -3.8642e-02, -8.1100e-02,  7.8877e-02,\n",
      "         -2.6337e-02,  8.8669e-02,  2.7319e-02, -7.9664e-02, -4.3216e-02,\n",
      "         -1.7553e-02,  1.4281e-01,  3.2445e-02,  7.0466e-02, -2.2125e-01,\n",
      "         -1.5452e-01, -3.6394e-02, -2.6400e-02, -2.2010e-01,  6.2533e-02,\n",
      "         -1.3467e-01,  1.0978e-01,  1.7734e-01,  3.4074e-02, -7.9925e-02,\n",
      "          1.7046e-01,  1.0419e-02,  5.8542e-02, -1.1312e-01, -6.4831e-02,\n",
      "         -2.3101e-02, -8.6798e-02, -1.3083e-01,  7.9250e-02,  5.3506e-02,\n",
      "          7.8940e-02, -1.8466e-01,  3.2029e-02,  1.7475e-01],\n",
      "        [ 1.0596e-02, -6.0197e-02,  8.1104e-02, -3.1139e-02,  6.9965e-02,\n",
      "         -4.5893e-02, -4.7197e-02, -1.3993e-01,  1.0881e-01, -4.9379e-02,\n",
      "         -1.0123e-01,  1.0999e-01, -6.4386e-02, -6.0447e-02, -1.5775e-01,\n",
      "          1.2937e-01, -1.3501e-01, -1.3112e-01,  8.3092e-02, -8.2259e-02,\n",
      "          4.0537e-02, -5.8182e-02, -1.5245e-01, -8.6686e-02, -3.5818e-01,\n",
      "          1.2154e-01,  5.9819e-02, -1.7174e-01,  3.9259e-02,  4.7649e-02,\n",
      "          1.3183e-01, -6.3177e-02, -4.1788e-02,  9.3505e-03,  1.3325e-01,\n",
      "         -6.3992e-02,  4.6938e-02, -3.0413e-02,  8.5952e-02,  6.9438e-02,\n",
      "         -5.4145e-02,  1.4373e-04, -1.4911e-01,  1.1178e-01, -2.7705e-03,\n",
      "         -3.2650e-02,  5.8303e-02, -1.8210e-01,  4.0653e-03, -1.3280e-02,\n",
      "          5.9250e-02,  4.9391e-03, -6.7734e-02,  1.7540e-01, -2.8536e-02,\n",
      "          9.5656e-02, -2.1606e-01,  2.2637e-02,  7.3654e-02, -2.2221e-01,\n",
      "         -1.6125e-01,  8.9250e-03, -1.3001e-01, -1.2322e-01,  5.7937e-02,\n",
      "          1.2183e-02, -7.3184e-02, -8.2231e-03,  9.5583e-02, -9.1207e-02,\n",
      "          4.3538e-02,  7.2025e-02,  1.5288e-02, -9.0877e-02,  4.3587e-02,\n",
      "          7.9371e-02, -3.6342e-02,  3.4559e-02, -2.5369e-02,  1.2938e-02,\n",
      "         -1.8183e-01,  5.5072e-02, -1.0161e-01,  4.4055e-02],\n",
      "        [-9.5411e-02,  6.5289e-02,  2.7340e-02,  2.1328e-02,  1.0074e-01,\n",
      "          2.0982e-02, -7.1259e-02, -9.3124e-02, -2.3112e-01,  3.3529e-02,\n",
      "         -1.2110e-01,  1.4751e-01,  6.1415e-02, -1.4328e-01,  1.3853e-01,\n",
      "         -7.1646e-02, -1.0408e-01,  5.0974e-02,  9.5835e-02,  1.2722e-01,\n",
      "         -1.5856e-01, -2.3764e-02, -1.2677e-01,  3.0766e-02,  1.8652e-01,\n",
      "          5.6118e-02,  2.7061e-02,  1.6550e-01,  3.4876e-02,  5.1588e-03,\n",
      "         -1.4197e-01, -6.7259e-03,  2.9582e-02,  1.7240e-01, -2.3113e-01,\n",
      "         -1.3239e-01, -5.5899e-03,  8.0393e-02,  2.1079e-02, -1.9733e-01,\n",
      "          8.6457e-02,  7.8377e-02, -5.7759e-02, -1.2086e-01, -1.0473e-01,\n",
      "         -2.1259e-01, -1.8163e-02, -1.3021e-01,  6.7297e-03,  6.8021e-02,\n",
      "          1.3573e-02, -7.5904e-02, -8.8456e-02,  1.3290e-02, -5.0047e-02,\n",
      "         -8.0180e-03, -3.9624e-02,  5.7315e-02,  4.1187e-02,  1.7819e-01,\n",
      "          7.9674e-02,  6.9348e-02,  1.8390e-01,  1.2136e-01,  4.3563e-02,\n",
      "          1.4928e-01, -3.3819e-02,  1.0565e-01, -5.4643e-02, -6.2852e-02,\n",
      "         -7.0927e-02, -1.2701e-02, -1.8689e-03, -5.7231e-02,  8.6276e-03,\n",
      "         -3.8894e-03,  7.3125e-02,  5.4542e-02, -9.1990e-02, -3.5726e-02,\n",
      "         -6.7105e-02, -6.1969e-02, -5.9669e-02,  7.4857e-02],\n",
      "        [-6.4341e-02, -7.4023e-02,  1.0424e-02, -3.9382e-02,  6.2722e-02,\n",
      "          8.2827e-02, -1.1688e-01, -4.6853e-03,  1.5380e-01,  6.6330e-02,\n",
      "          5.8838e-02, -1.7021e-01,  8.1381e-02,  8.3439e-02,  9.1344e-02,\n",
      "         -4.6016e-02, -1.4215e-01, -7.6437e-02, -6.1344e-02, -1.3094e-01,\n",
      "          1.1810e-01, -2.5911e-02,  3.5861e-02, -1.1691e-02, -1.8751e-01,\n",
      "         -2.5742e-02,  1.3303e-02, -1.7247e-01, -8.6034e-02, -2.4785e-02,\n",
      "          7.4426e-02,  6.4604e-02,  4.0883e-02, -5.8499e-03,  5.3122e-03,\n",
      "         -1.1213e-01,  7.1401e-02,  1.2422e-01,  7.2224e-02,  4.5610e-02,\n",
      "          1.5718e-01,  1.0788e-02,  1.9273e-02,  1.9930e-02,  1.4554e-01,\n",
      "         -8.5793e-02,  5.3025e-02,  1.5696e-01,  2.2640e-02,  1.1003e-01,\n",
      "         -8.0792e-02, -3.6788e-03, -8.2936e-03, -8.7757e-02, -1.2188e-01,\n",
      "          6.6378e-02,  1.0303e-01, -1.6743e-01, -5.0371e-02,  8.3801e-02,\n",
      "         -1.3847e-02, -2.2878e-02,  6.6867e-02,  1.6358e-01,  2.3600e-02,\n",
      "         -2.0803e-02, -6.2154e-03, -1.9954e-01, -3.2075e-02, -1.1166e-01,\n",
      "          5.1360e-02, -6.0833e-02, -1.3168e-01, -1.0029e-01, -6.1007e-02,\n",
      "          1.5514e-01,  4.3452e-02,  8.6109e-02, -7.0580e-03,  3.2560e-02,\n",
      "         -1.5678e-01, -1.4989e-01,  4.0337e-02, -1.5467e-01],\n",
      "        [-8.7456e-02, -4.5858e-02,  8.7830e-02, -8.2535e-02,  1.2863e-01,\n",
      "         -1.8876e-01,  1.3549e-01,  9.7784e-02, -6.7000e-02,  9.1333e-02,\n",
      "         -7.3883e-02, -2.4618e-01,  9.0446e-02, -1.1941e-02,  6.9856e-02,\n",
      "         -1.3691e-02,  1.6113e-01, -5.1353e-02, -1.8522e-01, -2.4898e-01,\n",
      "          5.6747e-02,  1.1095e-01, -8.4380e-02,  7.0721e-02,  4.2050e-02,\n",
      "         -5.3164e-02, -7.4864e-04,  7.4255e-02,  5.6526e-02, -2.4998e-01,\n",
      "         -2.7485e-02,  6.6945e-02,  2.1406e-02,  9.5890e-03, -5.3929e-02,\n",
      "         -1.8225e-02, -9.1344e-02, -1.9311e-01, -6.9763e-02,  3.2313e-02,\n",
      "         -4.2170e-02,  1.3273e-01,  5.9123e-02,  1.4404e-01,  6.2153e-03,\n",
      "          3.9200e-02,  9.5516e-02,  1.6023e-01,  1.8831e-02, -3.5646e-02,\n",
      "         -7.7185e-02, -1.1330e-01, -3.5243e-02, -1.9530e-01,  3.2132e-02,\n",
      "         -1.9641e-01, -2.5863e-01, -3.0647e-01, -8.1839e-03,  1.2389e-01,\n",
      "          1.1218e-01,  1.1897e-02,  7.7755e-02,  1.7283e-01,  4.9961e-02,\n",
      "         -8.2112e-02, -1.1825e-02, -2.1986e-01, -4.7570e-02, -1.2469e-01,\n",
      "          1.5893e-02,  1.2552e-01, -7.3013e-03, -1.0933e-01, -3.9250e-02,\n",
      "         -1.0709e-01,  2.8763e-02,  5.8371e-02, -6.1101e-02, -4.1192e-02,\n",
      "         -1.1198e-01, -1.1348e-01, -1.4154e-01,  6.7206e-02],\n",
      "        [ 7.5002e-02, -5.5931e-02, -4.9224e-02, -1.0399e-01, -9.3695e-02,\n",
      "          5.1030e-02, -1.8146e-01,  7.1248e-02,  4.9916e-02, -5.8669e-02,\n",
      "          1.5068e-01,  5.2943e-02,  6.2673e-02, -1.6827e-01, -3.1714e-02,\n",
      "         -1.0850e-01,  3.9289e-02,  8.5719e-02,  6.6596e-02,  5.2551e-02,\n",
      "          6.2875e-03,  2.3058e-01,  1.3481e-01, -2.1767e-01, -2.6383e-02,\n",
      "          1.2935e-01, -7.0947e-02, -1.0321e-01,  1.6183e-02,  1.1551e-01,\n",
      "         -9.8106e-02, -2.8911e-02,  1.1200e-01,  1.7346e-02,  1.2221e-01,\n",
      "         -9.0078e-02, -1.3969e-02,  6.6038e-02,  4.9758e-02, -3.5310e-02,\n",
      "         -1.2505e-01,  7.5139e-02, -4.0238e-02, -1.7975e-01, -2.7260e-01,\n",
      "          2.3728e-02, -6.4905e-02, -3.6330e-02, -1.7522e-02, -1.7668e-01,\n",
      "          5.3235e-02, -3.2876e-02, -8.2446e-02, -5.6357e-02,  5.4981e-02,\n",
      "          9.7365e-03,  1.6405e-01,  1.2919e-01, -1.2985e-01, -1.3701e-01,\n",
      "          2.0801e-01, -1.1266e-01, -1.7384e-01, -1.0546e-01, -3.6028e-03,\n",
      "          7.5735e-02,  2.2825e-02, -4.7430e-02, -4.6450e-03,  1.9538e-01,\n",
      "          1.5488e-01, -4.7458e-02,  4.5838e-02,  1.7703e-02,  7.5227e-02,\n",
      "          9.3142e-02,  5.4819e-02, -1.4666e-01,  7.7283e-02, -5.2386e-02,\n",
      "          4.1662e-02,  1.5161e-01,  6.5397e-02,  1.2102e-01],\n",
      "        [-6.9985e-02, -1.3762e-01, -7.6682e-02, -1.1277e-01,  3.7370e-02,\n",
      "         -7.7481e-02, -2.8908e-02, -3.5950e-03,  2.5220e-02,  1.2427e-02,\n",
      "          2.4083e-03, -6.8745e-02,  4.3429e-02,  5.7242e-02,  4.3172e-02,\n",
      "         -1.0241e-01,  1.3391e-01, -1.0175e-01,  2.7414e-02,  5.7122e-02,\n",
      "          7.7533e-02,  4.5603e-04, -7.1188e-02,  4.6102e-02, -1.2245e-01,\n",
      "         -1.6095e-01,  7.0553e-02,  1.6468e-02, -6.3812e-02,  1.6716e-01,\n",
      "          4.8101e-02, -3.7791e-02, -6.0261e-02, -2.3909e-01,  5.3279e-03,\n",
      "          1.0027e-01, -7.9409e-03, -2.3220e-01, -5.6190e-02, -1.0099e-01,\n",
      "          1.7174e-01,  7.9553e-02, -5.4270e-02,  5.7433e-02,  1.4037e-01,\n",
      "          1.3020e-01, -1.3627e-01, -9.9093e-02, -1.1088e-01, -3.5412e-02,\n",
      "          4.7989e-02,  8.9716e-02, -5.7217e-02,  1.5921e-01, -6.5628e-02,\n",
      "          2.9890e-02, -2.0708e-02,  7.5548e-02,  1.5058e-01, -1.3844e-01,\n",
      "         -5.6506e-02,  4.0326e-02, -9.3453e-02, -1.8012e-02,  7.5456e-02,\n",
      "          3.2095e-02,  1.4767e-01, -2.7028e-01,  1.1446e-01, -7.2654e-02,\n",
      "         -1.5999e-01,  1.2320e-01, -6.6792e-02, -7.0690e-02, -1.1658e-03,\n",
      "         -7.3680e-02,  9.6174e-02, -1.7620e-01,  6.5879e-02, -4.4506e-02,\n",
      "         -9.7249e-02, -1.2168e-01,  6.5070e-02, -7.1690e-02],\n",
      "        [-1.1543e-02,  7.9138e-02,  6.8700e-03,  8.5682e-02, -7.3814e-03,\n",
      "          3.8741e-02, -6.1681e-02, -3.0741e-02, -8.2886e-02, -6.0744e-02,\n",
      "          8.0962e-02,  5.5822e-02, -6.4783e-02,  2.0637e-02,  1.5480e-01,\n",
      "         -1.7832e-01, -7.5911e-02,  1.3977e-01, -7.0417e-03,  1.1538e-01,\n",
      "         -2.1057e-02, -2.7627e-01,  8.0313e-02,  9.0965e-02, -2.1224e-02,\n",
      "          8.7942e-02,  4.6768e-02,  4.1808e-02, -6.0969e-04,  5.0881e-02,\n",
      "         -1.0346e-01, -9.5099e-02, -9.6930e-02,  1.6046e-01,  1.0340e-01,\n",
      "         -1.2049e-01,  4.7386e-02,  1.4371e-01,  1.0732e-01,  1.4874e-02,\n",
      "         -1.4698e-02, -2.3645e-01, -2.2436e-02,  7.0707e-02,  1.3104e-01,\n",
      "         -9.9199e-02, -1.2637e-01,  7.3979e-02, -8.3617e-02,  4.9549e-02,\n",
      "         -3.3602e-02, -6.9785e-03, -1.1291e-03,  1.2687e-01, -7.3812e-02,\n",
      "          1.4657e-01, -1.1370e-01,  1.0816e-01,  6.3336e-02, -2.4276e-02,\n",
      "         -6.3137e-02, -6.7445e-02, -1.0885e-01, -3.7241e-03,  2.8797e-03,\n",
      "          1.9368e-01, -1.5737e-01,  5.2590e-02,  9.9306e-02,  4.5265e-02,\n",
      "         -7.3044e-02, -1.9899e-01, -3.5704e-01, -3.9435e-02,  4.4111e-02,\n",
      "         -1.0589e-01, -8.8305e-02,  1.1836e-01,  2.2790e-02, -2.9184e-02,\n",
      "         -1.8088e-01,  7.4564e-05,  1.4839e-01, -2.3518e-01]])\n",
      "====================================================\n",
      "tensor([[ 5.7502e-02, -4.7653e-02, -8.4562e-02, -2.5373e-02,  5.7231e-02,\n",
      "         -2.3991e-01, -5.8743e-02,  1.3909e-01,  3.4454e-02, -1.2096e-02,\n",
      "         -3.5502e-02, -1.2316e-01, -6.2097e-03, -7.2736e-02,  7.9141e-02,\n",
      "          1.6031e-02,  1.3602e-01, -1.0817e-01, -1.3844e-01,  2.8183e-02,\n",
      "         -1.0384e-01, -2.7578e-01,  1.7877e-01, -1.6349e-01, -1.2095e-01,\n",
      "          2.6431e-02, -1.1178e-01, -2.9428e-02,  6.2005e-02, -1.5256e-01,\n",
      "          6.1777e-02, -7.3393e-02, -1.9656e-01,  6.7498e-02, -1.2652e-02,\n",
      "          1.1367e-01, -3.6797e-02, -2.3679e-02,  1.5724e-01,  1.0304e-01,\n",
      "         -1.5883e-01, -7.2645e-02, -9.6742e-02,  6.9922e-02,  2.8612e-02,\n",
      "          7.6805e-02,  5.4769e-02,  5.9486e-02, -3.2537e-02,  1.4885e-01,\n",
      "         -4.3388e-02,  2.4472e-02, -4.7109e-02,  2.8444e-02,  2.4384e-03,\n",
      "         -1.3648e-01,  1.1871e-02, -6.9804e-02, -1.2491e-02,  5.7567e-02,\n",
      "         -2.4205e-02,  2.0895e-02, -7.3688e-02, -7.9895e-02, -8.4406e-02,\n",
      "          1.3331e-01,  1.5363e-01,  1.8983e-01, -2.1542e-01, -9.2696e-03,\n",
      "         -1.2719e-01, -5.7508e-02,  7.7498e-02,  3.0380e-02,  2.2764e-02,\n",
      "         -4.8476e-02, -3.9109e-02,  3.0797e-02, -1.1032e-01,  3.0609e-02,\n",
      "          2.0946e-01, -1.4476e-01, -1.5267e-01, -1.2615e-01],\n",
      "        [-1.0983e-01, -1.6643e-02, -5.4499e-02,  5.2598e-02,  1.1222e-01,\n",
      "          1.8281e-01, -1.6932e-01, -1.0697e-01, -1.5967e-01,  2.5727e-02,\n",
      "         -9.5816e-02, -1.7568e-02,  1.4565e-03, -1.1926e-01, -2.4998e-01,\n",
      "          8.7458e-03,  5.1587e-02,  1.2225e-01, -5.8399e-02,  8.9523e-02,\n",
      "          1.5307e-02,  1.0511e-01,  1.6931e-01, -1.0654e-01,  1.9253e-01,\n",
      "         -1.1609e-01, -1.1423e-02, -8.1835e-02,  2.6023e-02, -1.5318e-01,\n",
      "          1.0242e-01,  5.6021e-02, -2.4122e-02,  1.2591e-01, -1.9811e-01,\n",
      "         -1.2534e-01, -3.3369e-02, -2.6970e-01, -1.7313e-01, -1.3248e-01,\n",
      "         -6.7860e-02, -8.1787e-02, -1.0105e-01, -8.6901e-02,  1.2492e-01,\n",
      "          5.9038e-02,  7.3593e-02, -1.0772e-01, -8.4726e-03,  7.8861e-02,\n",
      "         -8.6169e-02, -9.9107e-02, -4.6772e-02,  1.0534e-01, -1.1536e-01,\n",
      "          3.9013e-02,  1.6768e-01,  3.9793e-02, -2.1685e-01,  1.6369e-01,\n",
      "         -2.1570e-01, -9.1211e-02, -5.6152e-02,  1.2030e-01,  4.9114e-02,\n",
      "         -1.0417e-01, -1.0169e-02,  3.5655e-02,  7.7145e-02,  1.5954e-01,\n",
      "          2.0149e-01,  1.4767e-01,  1.1135e-01, -2.6222e-02,  6.5729e-02,\n",
      "         -1.3869e-01, -1.0216e-01,  3.3140e-01, -9.7850e-02,  2.3685e-02,\n",
      "          1.5255e-01,  9.1470e-03, -1.1895e-01,  8.7839e-02],\n",
      "        [-1.1059e-01,  6.4744e-03,  6.7646e-02, -8.5198e-02, -3.6996e-02,\n",
      "          3.8133e-02,  1.4229e-01,  1.0586e-01, -7.2759e-02, -9.3293e-02,\n",
      "          5.8428e-02,  2.9989e-02,  1.7277e-02, -4.3939e-02, -4.3254e-02,\n",
      "          1.3321e-01,  9.4943e-02, -1.7466e-01, -5.1416e-03,  5.8932e-02,\n",
      "         -1.0059e-02, -1.2247e-01, -2.3295e-01, -1.3186e-01, -1.1138e-01,\n",
      "          5.2414e-02,  1.6524e-02, -6.7446e-02, -6.9809e-02, -3.7493e-02,\n",
      "          1.3993e-01,  1.7652e-02,  9.3298e-02,  1.3817e-01, -1.1945e-02,\n",
      "          8.6820e-02, -2.6956e-02,  1.2588e-01, -5.3166e-02, -4.8333e-02,\n",
      "         -1.1508e-01,  1.2482e-01, -4.6368e-02, -5.9391e-04, -3.2709e-02,\n",
      "         -1.4332e-01, -2.6776e-01, -3.8642e-02, -8.1100e-02,  7.8877e-02,\n",
      "         -2.6337e-02,  8.8669e-02,  2.7319e-02, -7.9664e-02, -4.3216e-02,\n",
      "         -1.7553e-02,  1.4281e-01,  3.2445e-02,  7.0466e-02, -2.2125e-01,\n",
      "         -1.5452e-01, -3.6394e-02, -2.6400e-02, -2.2010e-01,  6.2533e-02,\n",
      "         -1.3467e-01,  1.0978e-01,  1.7734e-01,  3.4074e-02, -7.9925e-02,\n",
      "          1.7046e-01,  1.0419e-02,  5.8542e-02, -1.1312e-01, -6.4831e-02,\n",
      "         -2.3101e-02, -8.6798e-02, -1.3083e-01,  7.9250e-02,  5.3506e-02,\n",
      "          7.8940e-02, -1.8466e-01,  3.2029e-02,  1.7475e-01],\n",
      "        [ 1.0596e-02, -6.0197e-02,  8.1104e-02, -3.1139e-02,  6.9965e-02,\n",
      "         -4.5893e-02, -4.7197e-02, -1.3993e-01,  1.0881e-01, -4.9379e-02,\n",
      "         -1.0123e-01,  1.0999e-01, -6.4386e-02, -6.0447e-02, -1.5775e-01,\n",
      "          1.2937e-01, -1.3501e-01, -1.3112e-01,  8.3092e-02, -8.2259e-02,\n",
      "          4.0537e-02, -5.8182e-02, -1.5245e-01, -8.6686e-02, -3.5818e-01,\n",
      "          1.2154e-01,  5.9819e-02, -1.7174e-01,  3.9259e-02,  4.7649e-02,\n",
      "          1.3183e-01, -6.3177e-02, -4.1788e-02,  9.3505e-03,  1.3325e-01,\n",
      "         -6.3992e-02,  4.6938e-02, -3.0413e-02,  8.5952e-02,  6.9438e-02,\n",
      "         -5.4145e-02,  1.4373e-04, -1.4911e-01,  1.1178e-01, -2.7705e-03,\n",
      "         -3.2650e-02,  5.8303e-02, -1.8210e-01,  4.0653e-03, -1.3280e-02,\n",
      "          5.9250e-02,  4.9391e-03, -6.7734e-02,  1.7540e-01, -2.8536e-02,\n",
      "          9.5656e-02, -2.1606e-01,  2.2637e-02,  7.3654e-02, -2.2221e-01,\n",
      "         -1.6125e-01,  8.9250e-03, -1.3001e-01, -1.2322e-01,  5.7937e-02,\n",
      "          1.2183e-02, -7.3184e-02, -8.2231e-03,  9.5583e-02, -9.1207e-02,\n",
      "          4.3538e-02,  7.2025e-02,  1.5288e-02, -9.0877e-02,  4.3587e-02,\n",
      "          7.9371e-02, -3.6342e-02,  3.4559e-02, -2.5369e-02,  1.2938e-02,\n",
      "         -1.8183e-01,  5.5072e-02, -1.0161e-01,  4.4055e-02],\n",
      "        [-9.5411e-02,  6.5289e-02,  2.7340e-02,  2.1328e-02,  1.0074e-01,\n",
      "          2.0982e-02, -7.1259e-02, -9.3124e-02, -2.3112e-01,  3.3529e-02,\n",
      "         -1.2110e-01,  1.4751e-01,  6.1415e-02, -1.4328e-01,  1.3853e-01,\n",
      "         -7.1646e-02, -1.0408e-01,  5.0974e-02,  9.5835e-02,  1.2722e-01,\n",
      "         -1.5856e-01, -2.3764e-02, -1.2677e-01,  3.0766e-02,  1.8652e-01,\n",
      "          5.6118e-02,  2.7061e-02,  1.6550e-01,  3.4876e-02,  5.1588e-03,\n",
      "         -1.4197e-01, -6.7259e-03,  2.9582e-02,  1.7240e-01, -2.3113e-01,\n",
      "         -1.3239e-01, -5.5899e-03,  8.0393e-02,  2.1079e-02, -1.9733e-01,\n",
      "          8.6457e-02,  7.8377e-02, -5.7759e-02, -1.2086e-01, -1.0473e-01,\n",
      "         -2.1259e-01, -1.8163e-02, -1.3021e-01,  6.7297e-03,  6.8021e-02,\n",
      "          1.3573e-02, -7.5904e-02, -8.8456e-02,  1.3290e-02, -5.0047e-02,\n",
      "         -8.0180e-03, -3.9624e-02,  5.7315e-02,  4.1187e-02,  1.7819e-01,\n",
      "          7.9674e-02,  6.9348e-02,  1.8390e-01,  1.2136e-01,  4.3563e-02,\n",
      "          1.4928e-01, -3.3819e-02,  1.0565e-01, -5.4643e-02, -6.2852e-02,\n",
      "         -7.0927e-02, -1.2701e-02, -1.8689e-03, -5.7231e-02,  8.6276e-03,\n",
      "         -3.8894e-03,  7.3125e-02,  5.4542e-02, -9.1990e-02, -3.5726e-02,\n",
      "         -6.7105e-02, -6.1969e-02, -5.9669e-02,  7.4857e-02],\n",
      "        [-6.4341e-02, -7.4023e-02,  1.0424e-02, -3.9382e-02,  6.2722e-02,\n",
      "          8.2827e-02, -1.1688e-01, -4.6853e-03,  1.5380e-01,  6.6330e-02,\n",
      "          5.8838e-02, -1.7021e-01,  8.1381e-02,  8.3439e-02,  9.1344e-02,\n",
      "         -4.6016e-02, -1.4215e-01, -7.6437e-02, -6.1344e-02, -1.3094e-01,\n",
      "          1.1810e-01, -2.5911e-02,  3.5861e-02, -1.1691e-02, -1.8751e-01,\n",
      "         -2.5742e-02,  1.3303e-02, -1.7247e-01, -8.6034e-02, -2.4785e-02,\n",
      "          7.4426e-02,  6.4604e-02,  4.0883e-02, -5.8499e-03,  5.3122e-03,\n",
      "         -1.1213e-01,  7.1401e-02,  1.2422e-01,  7.2224e-02,  4.5610e-02,\n",
      "          1.5718e-01,  1.0788e-02,  1.9273e-02,  1.9930e-02,  1.4554e-01,\n",
      "         -8.5793e-02,  5.3025e-02,  1.5696e-01,  2.2640e-02,  1.1003e-01,\n",
      "         -8.0792e-02, -3.6788e-03, -8.2936e-03, -8.7757e-02, -1.2188e-01,\n",
      "          6.6378e-02,  1.0303e-01, -1.6743e-01, -5.0371e-02,  8.3801e-02,\n",
      "         -1.3847e-02, -2.2878e-02,  6.6867e-02,  1.6358e-01,  2.3600e-02,\n",
      "         -2.0803e-02, -6.2154e-03, -1.9954e-01, -3.2075e-02, -1.1166e-01,\n",
      "          5.1360e-02, -6.0833e-02, -1.3168e-01, -1.0029e-01, -6.1007e-02,\n",
      "          1.5514e-01,  4.3452e-02,  8.6109e-02, -7.0580e-03,  3.2560e-02,\n",
      "         -1.5678e-01, -1.4989e-01,  4.0337e-02, -1.5467e-01],\n",
      "        [-8.7456e-02, -4.5858e-02,  8.7830e-02, -8.2535e-02,  1.2863e-01,\n",
      "         -1.8876e-01,  1.3549e-01,  9.7784e-02, -6.7000e-02,  9.1333e-02,\n",
      "         -7.3883e-02, -2.4618e-01,  9.0446e-02, -1.1941e-02,  6.9856e-02,\n",
      "         -1.3691e-02,  1.6113e-01, -5.1353e-02, -1.8522e-01, -2.4898e-01,\n",
      "          5.6747e-02,  1.1095e-01, -8.4380e-02,  7.0721e-02,  4.2050e-02,\n",
      "         -5.3164e-02, -7.4864e-04,  7.4255e-02,  5.6526e-02, -2.4998e-01,\n",
      "         -2.7485e-02,  6.6945e-02,  2.1406e-02,  9.5890e-03, -5.3929e-02,\n",
      "         -1.8225e-02, -9.1344e-02, -1.9311e-01, -6.9763e-02,  3.2313e-02,\n",
      "         -4.2170e-02,  1.3273e-01,  5.9123e-02,  1.4404e-01,  6.2153e-03,\n",
      "          3.9200e-02,  9.5516e-02,  1.6023e-01,  1.8831e-02, -3.5646e-02,\n",
      "         -7.7185e-02, -1.1330e-01, -3.5243e-02, -1.9530e-01,  3.2132e-02,\n",
      "         -1.9641e-01, -2.5863e-01, -3.0647e-01, -8.1839e-03,  1.2389e-01,\n",
      "          1.1218e-01,  1.1897e-02,  7.7755e-02,  1.7283e-01,  4.9961e-02,\n",
      "         -8.2112e-02, -1.1825e-02, -2.1986e-01, -4.7570e-02, -1.2469e-01,\n",
      "          1.5893e-02,  1.2552e-01, -7.3013e-03, -1.0933e-01, -3.9250e-02,\n",
      "         -1.0709e-01,  2.8763e-02,  5.8371e-02, -6.1101e-02, -4.1192e-02,\n",
      "         -1.1198e-01, -1.1348e-01, -1.4154e-01,  6.7206e-02],\n",
      "        [ 7.5002e-02, -5.5931e-02, -4.9224e-02, -1.0399e-01, -9.3695e-02,\n",
      "          5.1030e-02, -1.8146e-01,  7.1248e-02,  4.9916e-02, -5.8669e-02,\n",
      "          1.5068e-01,  5.2943e-02,  6.2673e-02, -1.6827e-01, -3.1714e-02,\n",
      "         -1.0850e-01,  3.9289e-02,  8.5719e-02,  6.6596e-02,  5.2551e-02,\n",
      "          6.2875e-03,  2.3058e-01,  1.3481e-01, -2.1767e-01, -2.6383e-02,\n",
      "          1.2935e-01, -7.0947e-02, -1.0321e-01,  1.6183e-02,  1.1551e-01,\n",
      "         -9.8106e-02, -2.8911e-02,  1.1200e-01,  1.7346e-02,  1.2221e-01,\n",
      "         -9.0078e-02, -1.3969e-02,  6.6038e-02,  4.9758e-02, -3.5310e-02,\n",
      "         -1.2505e-01,  7.5139e-02, -4.0238e-02, -1.7975e-01, -2.7260e-01,\n",
      "          2.3728e-02, -6.4905e-02, -3.6330e-02, -1.7522e-02, -1.7668e-01,\n",
      "          5.3235e-02, -3.2876e-02, -8.2446e-02, -5.6357e-02,  5.4981e-02,\n",
      "          9.7365e-03,  1.6405e-01,  1.2919e-01, -1.2985e-01, -1.3701e-01,\n",
      "          2.0801e-01, -1.1266e-01, -1.7384e-01, -1.0546e-01, -3.6028e-03,\n",
      "          7.5735e-02,  2.2825e-02, -4.7430e-02, -4.6450e-03,  1.9538e-01,\n",
      "          1.5488e-01, -4.7458e-02,  4.5838e-02,  1.7703e-02,  7.5227e-02,\n",
      "          9.3142e-02,  5.4819e-02, -1.4666e-01,  7.7283e-02, -5.2386e-02,\n",
      "          4.1662e-02,  1.5161e-01,  6.5397e-02,  1.2102e-01],\n",
      "        [-6.9985e-02, -1.3762e-01, -7.6682e-02, -1.1277e-01,  3.7370e-02,\n",
      "         -7.7481e-02, -2.8908e-02, -3.5950e-03,  2.5220e-02,  1.2427e-02,\n",
      "          2.4083e-03, -6.8745e-02,  4.3429e-02,  5.7242e-02,  4.3172e-02,\n",
      "         -1.0241e-01,  1.3391e-01, -1.0175e-01,  2.7414e-02,  5.7122e-02,\n",
      "          7.7533e-02,  4.5603e-04, -7.1188e-02,  4.6102e-02, -1.2245e-01,\n",
      "         -1.6095e-01,  7.0553e-02,  1.6468e-02, -6.3812e-02,  1.6716e-01,\n",
      "          4.8101e-02, -3.7791e-02, -6.0261e-02, -2.3909e-01,  5.3279e-03,\n",
      "          1.0027e-01, -7.9409e-03, -2.3220e-01, -5.6190e-02, -1.0099e-01,\n",
      "          1.7174e-01,  7.9553e-02, -5.4270e-02,  5.7433e-02,  1.4037e-01,\n",
      "          1.3020e-01, -1.3627e-01, -9.9093e-02, -1.1088e-01, -3.5412e-02,\n",
      "          4.7989e-02,  8.9716e-02, -5.7217e-02,  1.5921e-01, -6.5628e-02,\n",
      "          2.9890e-02, -2.0708e-02,  7.5548e-02,  1.5058e-01, -1.3844e-01,\n",
      "         -5.6506e-02,  4.0326e-02, -9.3453e-02, -1.8012e-02,  7.5456e-02,\n",
      "          3.2095e-02,  1.4767e-01, -2.7028e-01,  1.1446e-01, -7.2654e-02,\n",
      "         -1.5999e-01,  1.2320e-01, -6.6792e-02, -7.0690e-02, -1.1658e-03,\n",
      "         -7.3680e-02,  9.6174e-02, -1.7620e-01,  6.5879e-02, -4.4506e-02,\n",
      "         -9.7249e-02, -1.2168e-01,  6.5070e-02, -7.1690e-02],\n",
      "        [-1.1543e-02,  7.9138e-02,  6.8700e-03,  8.5682e-02, -7.3814e-03,\n",
      "          3.8741e-02, -6.1681e-02, -3.0741e-02, -8.2886e-02, -6.0744e-02,\n",
      "          8.0962e-02,  5.5822e-02, -6.4783e-02,  2.0637e-02,  1.5480e-01,\n",
      "         -1.7832e-01, -7.5911e-02,  1.3977e-01, -7.0417e-03,  1.1538e-01,\n",
      "         -2.1057e-02, -2.7627e-01,  8.0313e-02,  9.0965e-02, -2.1224e-02,\n",
      "          8.7942e-02,  4.6768e-02,  4.1808e-02, -6.0969e-04,  5.0881e-02,\n",
      "         -1.0346e-01, -9.5099e-02, -9.6930e-02,  1.6046e-01,  1.0340e-01,\n",
      "         -1.2049e-01,  4.7386e-02,  1.4371e-01,  1.0732e-01,  1.4874e-02,\n",
      "         -1.4698e-02, -2.3645e-01, -2.2436e-02,  7.0707e-02,  1.3104e-01,\n",
      "         -9.9199e-02, -1.2637e-01,  7.3979e-02, -8.3617e-02,  4.9549e-02,\n",
      "         -3.3602e-02, -6.9785e-03, -1.1291e-03,  1.2687e-01, -7.3812e-02,\n",
      "          1.4657e-01, -1.1370e-01,  1.0816e-01,  6.3336e-02, -2.4276e-02,\n",
      "         -6.3137e-02, -6.7445e-02, -1.0885e-01, -3.7241e-03,  2.8797e-03,\n",
      "          1.9368e-01, -1.5737e-01,  5.2590e-02,  9.9306e-02,  4.5265e-02,\n",
      "         -7.3044e-02, -1.9899e-01, -3.5704e-01, -3.9435e-02,  4.4111e-02,\n",
      "         -1.0589e-01, -8.8305e-02,  1.1836e-01,  2.2790e-02, -2.9184e-02,\n",
      "         -1.8088e-01,  7.4564e-05,  1.4839e-01, -2.3518e-01]])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gF8VGELNEAwW",
    "colab_type": "code",
    "outputId": "ffcb6684-1d5a-4a28-ff4f-6bdc2a97dab8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "print('Test acc: %0.2f, Train acc: %0.2f' % (evaluation(testloader,driftedmodel), evaluation(trainloader,driftedmodel)))"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Test acc: 98.73, Train acc: 98.76\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xzU5JwLPE3WG",
    "colab_type": "code",
    "outputId": "383e740c-535a-485c-c78a-d419eb0b80d6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "print('Test acc: %0.2f, Train acc: %0.2f' % (evaluation(testloader,intmodel), evaluation(trainloader,intmodel)))"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Test acc: 98.92, Train acc: 99.69\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "92GORzG_dMCX",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}